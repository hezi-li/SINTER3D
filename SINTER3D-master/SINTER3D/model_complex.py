import torch
import torch.optim as optim
import numpy as np
import pandas as pd
import scipy.sparse
from tqdm import tqdm
import os
from SINTER3D.networks_complex import DeconvNet
from SINTER3D.utils import set_seed
import json


def load_config(config_name_or_path):
    """ç®€å•çš„é…ç½®åŠ è½½å‡½æ•° - è‡ªåŠ¨å¤„ç†å¤šé…ç½®æ–‡ä»¶"""
    if config_name_or_path is None:
        return {}
    
    config_key = None
    if ':' in str(config_name_or_path):
        file_part, config_key = str(config_name_or_path).split(':', 1)
        config_name_or_path = file_part
    
    if config_name_or_path.endswith('.json'):
        config_path = config_name_or_path
    else:
        config_path = f"./configs/{config_name_or_path}.json"
    
    try:
        with open(config_path, 'r') as f:
            config_data = json.load(f)
        
        if config_key is not None:
            if config_key in config_data:
                print(f"âœ… Loaded configuration '{config_key}' from {config_path}")
                return config_data[config_key]
            else:
                print(f"âŒ Error: Config '{config_key}' not found. Available: {list(config_data.keys())}")
                return {}
        
        # å¦‚æœè¿™æ˜¯å¤šé…ç½®æ–‡ä»¶
        if isinstance(config_data, dict) and all(isinstance(v, dict) for v in config_data.values()):
            available_keys = list(config_data.keys())
            print(f"âš ï¸ Multiple configs found: {available_keys}")
            print("Please specify config using 'filename.json:config_name' format")
            print(f"Using '{available_keys[0]}' as default")
            return config_data[available_keys[0]]
        else:
            return config_data
            
    except FileNotFoundError:
        print(f"âš ï¸ Warning: Config file '{config_path}' not found, using default parameters")
        return {}


class Model():
    def __init__(self, adata_st_list_raw, adata_st, adata_basis, slice_idx,
                config=None,
                hidden_dims=[512, 128],
                slice_emb_dim=16,
                training_steps=11,
                lr=0.001,
                seed=2025,
                patience=200,
                mid_channel=200,
                save_path='./results_DLPFC',
                use_type='train',
                normalize=100,
                alpha_poisson = 5,
                lambda_feature = 1,
                gamma_feature = 2
                ):

        # 1ï¸âƒ£ é»˜è®¤å‚æ•°æ”¶é›†
        params = dict(
            hidden_dims=hidden_dims,
            slice_emb_dim=slice_emb_dim,
            training_steps=training_steps,
            lr=lr,
            seed=seed,
            patience=patience,
            mid_channel=mid_channel,
            save_path=save_path,
            use_type=use_type,
            normalize=normalize,
            alpha_poisson = alpha_poisson,
            lambda_feature = lambda_feature,
            gamma_feature = gamma_feature
        )

        # 2ï¸âƒ£ åŠ è½½å¹¶è¦†ç›–é»˜è®¤å€¼
        if config is not None:
            config_params = load_config(config)
            print("ğŸ“„ Config parameters loaded:", config_params)
            params.update(config_params) 

        # 3ï¸âƒ£ èµ‹å€¼åˆ°ç±»å±æ€§
        for k, v in params.items():
            setattr(self, k, v)

        # 4ï¸âƒ£ å¯åŠ¨æ—¶æ‰“å°æœ€ç»ˆç”Ÿæ•ˆå‚æ•°
        print("\nâœ… Final parameters used in Model:")
        for k in params.keys():
            print(f"  {k}: {getattr(self, k)}")
        print()

        # å›ºå®šéƒ¨åˆ†
        set_seed(self.seed)
        self.adata_basis = adata_basis
        self.adata_st = adata_st
        self.celltypes = list(adata_basis.obs.index)
        self.adata_st_list_raw = adata_st_list_raw
        self.slice_idx = slice_idx
        
        # slice ç¼–ç 
        unique_slices = sorted(self.adata_st.obs["slice"].unique())
        self.slice_remap = {old: i for i, old in enumerate(unique_slices)}
        self.adata_st.obs["slice"] = self.adata_st.obs["slice"].map(self.slice_remap).astype(int)

        # è®¾å¤‡
        self.device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")

        # è¿™é‡Œç”¨ self.hidden_dimsï¼ˆå·²è¢« config è¦†ç›–ï¼‰
        self.hidden_dims = [adata_st.shape[1]] + self.hidden_dims
        self.n_celltype = adata_basis.shape[0]
        self.n_slices = len(unique_slices)

        # æ„å»ºç½‘ç»œ
        self.net = DeconvNet(
            hidden_dims=self.hidden_dims,
            n_celltypes=self.n_celltype,
            n_slices=self.n_slices,
            slice_emb_dim=self.slice_emb_dim,
            training_steps=self.training_steps,
            mid_channel=self.mid_channel,
            alpha_poisson = self.alpha_poisson,
            lambda_feature = self.lambda_feature,
            gamma_feature = self.gamma_feature
        ).to(self.device)

        # ä¼˜åŒ–å™¨
        self.optimizer = optim.Adamax(list(self.net.parameters()), lr=self.lr)

        # æ•°æ®åŠ è½½
        if scipy.sparse.issparse(adata_st.X):
            self.X = torch.from_numpy(adata_st.X.toarray()).float().to(self.device)
        else:
            self.X = torch.from_numpy(adata_st.X).float().to(self.device)

        self.Y = torch.from_numpy(np.array(adata_st.obsm["count"])).float().to(self.device)
        self.lY = torch.from_numpy(np.array(adata_st.obs["library_size"].values.reshape(-1, 1))).float().to(self.device)
        self.slice = torch.from_numpy(np.array(adata_st.obs["slice"].values)).long().to(self.device)
        self.basis = torch.from_numpy(np.array(adata_basis.X)).float().to(self.device)
        self.coord = torch.from_numpy(np.array(adata_st.obsm['3D_coor'])).float().to(self.device)
        
    def train(self, report_loss=True, step_interval=1000, min_delta=1e-4):
        """
        è®­ç»ƒæ¨¡å‹ï¼Œæ”¯æŒæ—©åœæœºåˆ¶
        min_delta: Loss æ”¹å–„çš„æœ€å°å¹…åº¦ï¼Œå°äºè¿™ä¸ªå€¼è®¤ä¸ºæ²¡æœ‰è¿›æ­¥
        """
        self.net.train()

        best_loss = float('inf')     # å½“å‰æœ€ä½³loss
        best_state = None            # ä¿å­˜æœ€ä½³æ¨¡å‹çŠ¶æ€
        wait_count = 0               # ç­‰å¾…è®¡æ•°å™¨

        for step in tqdm(range(self.net.training_steps)):
            # å‰å‘è®¡ç®—
            loss, Z_teacher, denoise, coord_loss = self.net(
                coord=self.coord,
                node_feats=self.X,
                count_matrix=self.Y,
                library_size=self.lY,
                slice_label=self.slice,
                basis=self.basis,
                c=self.normalize,
                step=step
            )

            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()

            # æ—¥å¿—
            if report_loss and step % step_interval == 0:
                print(f"[Step {step}] Loss={loss.item():.6f} | CoordLoss={coord_loss.item():.6f} | Best={best_loss:.6f}")

            # --------- æ—©åœé€»è¾‘ -----------
            if best_loss - loss.item() > min_delta:
                # Loss æœ‰æ˜¾è‘—æ”¹å–„ï¼Œæ›´æ–°æœ€ä½³æ¨¡å‹ä¿¡æ¯
                best_loss = loss.item()
                best_state = {
                    'model': self.net.state_dict(),
                    'optimizer': self.optimizer.state_dict()
                }
                wait_count = 0
            else:
                # æ²¡æœ‰æ”¹å–„
                wait_count += 1

            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡ patience
            if wait_count >= self.patience:
                print(f"â¹ Early stopping triggered at step {step} | Best Loss={best_loss:.6f}")
                break

        # æ¢å¤æœ€ä½³æ¨¡å‹
        if best_state is not None:
            self.net.load_state_dict(best_state['model'])
            self.optimizer.load_state_dict(best_state['optimizer'])
            print("âœ… Loaded best model state from training.")



    def inference_latent(self, adata_new, coord_key="3D_coor", coord_only=False, decode=False):
        self.net.eval()
        coord_new = torch.from_numpy(np.array(adata_new.obsm[coord_key])).float().to(self.device)

        with torch.no_grad():
            Z_new, _ = self.net.inference_encoder(coord_new, coord_only=coord_only)
            if decode and not coord_only:
                X_pred = self.net.decoder(Z_new)
                adata_new.obsm["X_pred"] = X_pred.cpu().numpy()

        adata_new.obsm["latent"] = Z_new.cpu().numpy()
        return adata_new
    

    
    def eval(self, adata_st_list_raw, save=False, output_path="./results"):
        self.net.eval()
        self.Z, self.beta, self.alpha, self.gamma = self.net.evaluate(
            self.coord, self.X, self.slice
        )

        # å¤„ç†å¹¶ä¿å­˜æ½œåœ¨åµŒå…¥ï¼ˆrepresentation.csvï¼‰
        embeddings = self.Z.detach().cpu().numpy()
        cell_reps = pd.DataFrame(embeddings)
        cell_reps.index = self.adata_st.obs.index
        self.adata_st.obsm['latent'] = cell_reps.loc[self.adata_st.obs_names, ].values
        self.latent = cell_reps.loc[self.adata_st.obs_names, ].values

        # å¤„ç†åå·ç§¯ç»“æœ
        b = self.beta.detach().cpu().numpy()
        n_spots = 0
        adata_st_decon_list = []
        decon_results_all = []  # æ–°å¢ï¼šç”¨äºæ”¶é›†æ‰€æœ‰åˆ‡ç‰‡çš„åå·ç§¯ç»“æœ

        for i, adata_st_i in enumerate(adata_st_list_raw):
            adata_st_i = adata_st_i.copy()

            # ç´¢å¼•å¤„ç†ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
            if self.use_type == 'evaluate':
                if not all(idx.endswith(f"-slice{slice_val}") 
                        for idx, slice_val in zip(adata_st_i.obs.index, adata_st_i.obs['slice'])):
                    adata_st_i.obs.index = [
                        f"{idx}-slice{slice_val}" for idx, slice_val in zip(
                            adata_st_i.obs.index, adata_st_i.obs['slice']
                        )
                    ]
            else:
                if not all(idx.endswith(f"-slice{i}") for idx in adata_st_i.obs.index):
                    adata_st_i.obs.index = [f"{idx}-slice{i}" for idx in adata_st_i.obs.index]

            # ç”Ÿæˆå½“å‰åˆ‡ç‰‡çš„åå·ç§¯ç»“æœ
            decon_res = pd.DataFrame(
                b[n_spots:(n_spots + adata_st_i.shape[0]), :],
                columns=self.celltypes
            )
            decon_res.index = adata_st_i.obs.index
            decon_results_all.append(decon_res)  # æ–°å¢ï¼šæ”¶é›†å½“å‰åˆ‡ç‰‡ç»“æœ

            # åˆå¹¶åˆ°adataï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
            adata_st_i_obs = adata_st_i.obs.drop(columns=self.celltypes, errors="ignore")
            adata_st_i.obs = adata_st_i_obs.join(decon_res)

            n_spots += adata_st_i.shape[0]
            adata_st_decon_list.append(adata_st_i)

        # æ–°å¢ï¼šä¿å­˜æ–‡ä»¶ï¼ˆå½“save=Trueæ—¶ï¼‰
        if save:

            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ï¼ˆé¿å…è·¯å¾„ä¸å­˜åœ¨æŠ¥é”™ï¼‰
            os.makedirs(output_path, exist_ok=True)
            # ä¿å­˜æ½œåœ¨åµŒå…¥
            cell_reps.to_csv(os.path.join(output_path, "representation.csv"))
            # åˆå¹¶æ‰€æœ‰åˆ‡ç‰‡çš„åå·ç§¯ç»“æœå¹¶ä¿å­˜
            decon_results_combined = pd.concat(decon_results_all)
            decon_results_combined.to_csv(os.path.join(output_path, "deconvolution_results.csv"))


        return adata_st_decon_list


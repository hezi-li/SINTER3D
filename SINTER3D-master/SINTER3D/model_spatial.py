import torch
import torch.optim as optim
import numpy as np
import pandas as pd
import scipy.sparse
from tqdm import tqdm
import os
from SINTER3D.networks_spatial import DeconvNet
from SINTER3D.utils import set_seed
import json


def load_config(config_name_or_path):
    """åŠ è½½é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒå•æ–‡ä»¶æˆ–å¤šé…ç½®"""
    if config_name_or_path is None:
        return {}
    
    config_key = None
    if ':' in str(config_name_or_path):
        file_part, config_key = str(config_name_or_path).split(':', 1)
        config_name_or_path = file_part
    
    if config_name_or_path.endswith('.json'):
        config_path = config_name_or_path
    else:
        config_path = f"./configs/{config_name_or_path}.json"
    
    try:
        with open(config_path, 'r') as f:
            config_data = json.load(f)
        
        if config_key is not None:
            if config_key in config_data:
                print(f"âœ… Loaded configuration '{config_key}' from {config_path}")
                return config_data[config_key]
            else:
                print(f"âŒ Error: Config '{config_key}' not found. Available: {list(config_data.keys())}")
                return {}
        
        if isinstance(config_data, dict) and all(isinstance(v, dict) for v in config_data.values()):
            available_keys = list(config_data.keys())
            print(f"âš ï¸ Multiple configs found: {available_keys}")
            print(f"Using '{available_keys[0]}' as default")
            return config_data[available_keys[0]]
        else:
            return config_data
            
    except FileNotFoundError:
        print(f"âš ï¸ Warning: Config file '{config_path}' not found, using default parameters")
        return {}


class Model():
    def __init__(self, adata_st_list_raw, adata_st, adata_basis, slice_idx,
                 config=None, 
                 hidden_dims=[512, 128],
                 slice_emb_dim=16,
                 training_steps=11,
                 lr=0.001,
                 seed=2025,
                 patience=200,
                 mid_channel=200,
                 save_path='./results_DLPFC',
                 use_type='train',
                 normalize=100,
                 coord_emb_dim=64,   
                 num_freqs=6,         
                 alpha_poisson = 5,
                 lambda_feature = 1,
                 gamma_feature = 2
                 ):

        # 1ï¸âƒ£ æ”¶é›†é»˜è®¤å‚æ•°
        params = dict(
            hidden_dims=hidden_dims,
            slice_emb_dim=slice_emb_dim,
            training_steps=training_steps,
            lr=lr,
            seed=seed,
            patience=patience,
            mid_channel=mid_channel,
            save_path=save_path,
            use_type=use_type,
            normalize=normalize,
            coord_emb_dim=coord_emb_dim,
            num_freqs=num_freqs,
            alpha_poisson = alpha_poisson,
            lambda_feature = lambda_feature,
            gamma_feature = gamma_feature
        )

        # 2ï¸âƒ£ è¯»å– config è¦†ç›–é»˜è®¤å€¼
        if config is not None:
            config_params = load_config(config)
            print("ğŸ“„ Config parameters loaded:", config_params)
            params.update(config_params)  # config ä¼˜å…ˆçº§é«˜äºé»˜è®¤å€¼

        # 3ï¸âƒ£ å…¨éƒ¨èµ‹å€¼åˆ° self
        for k, v in params.items():
            setattr(self, k, v)

        # 4ï¸âƒ£ æ‰“å°æœ€ç»ˆç”Ÿæ•ˆå‚æ•°ï¼ˆè°ƒè¯•ç”¨ï¼‰
        print("\nâœ… Final parameters used in Model:")
        for k in params.keys():
            print(f"  {k}: {getattr(self, k)}")
        print()

        # ---- æ¥ä¸‹æ¥å›ºå®šåˆå§‹åŒ–éƒ¨åˆ† ----
        set_seed(self.seed)
        self.adata_basis = adata_basis
        self.adata_st = adata_st
        self.celltypes = list(adata_basis.obs.index)
        self.adata_st_list_raw = adata_st_list_raw
        self.slice_idx = slice_idx

        # slice ç¼–ç 
        unique_slices = sorted(self.adata_st.obs["slice"].unique())
        self.slice_remap = {old: i for i, old in enumerate(unique_slices)}
        self.adata_st.obs["slice"] = self.adata_st.obs["slice"].map(self.slice_remap).astype(int)

        # è®¾å¤‡
        self.device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")

        # ç¡®è®¤ hidden_dims æ ¼å¼
        self.hidden_dims = [adata_st.shape[1]] + self.hidden_dims
        self.n_celltype = adata_basis.shape[0]
        self.n_slices = len(unique_slices)

        # æ„å»ºç½‘ç»œ
        self.net = DeconvNet(
            hidden_dims=self.hidden_dims,
            n_celltypes=self.n_celltype,
            n_slices=self.n_slices,
            slice_emb_dim=self.slice_emb_dim,
            training_steps=self.training_steps,
            mid_channel=self.mid_channel,
            coord_emb_dim=self.coord_emb_dim,
            num_freqs=self.num_freqs,
            c = normalize,
            alpha_poisson = self.alpha_poisson,
            lambda_feature = self.lambda_feature,
            gamma_feature = self.gamma_feature
        ).to(self.device)

        # ä¼˜åŒ–å™¨
        self.optimizer = optim.Adamax(list(self.net.parameters()), lr=self.lr)

        # è¯»å–æ•°æ®
        if scipy.sparse.issparse(adata_st.X):
            self.X = torch.from_numpy(adata_st.X.toarray()).float().to(self.device)
        else:
            self.X = torch.from_numpy(adata_st.X).float().to(self.device)

        self.Y = torch.from_numpy(np.array(adata_st.obsm["count"])).float().to(self.device)
        self.lY = torch.from_numpy(np.array(adata_st.obs["library_size"].values.reshape(-1, 1))).float().to(self.device)
        self.slice = torch.from_numpy(np.array(adata_st.obs["slice"].values)).long().to(self.device)
        self.basis = torch.from_numpy(np.array(adata_basis.X)).float().to(self.device)
        self.coord = torch.from_numpy(np.array(adata_st.obsm['3D_coor'])).float().to(self.device)

        # --------- train with early stopping ---------
    def train(self, report_loss=True, step_interval=1000, min_delta=1e-4):
        """
        è®­ç»ƒæ¨¡å‹ï¼Œæ”¯æŒæ—©åœ
        min_delta: loss æ”¹å–„çš„æœ€å°å¹…åº¦ï¼Œå°äºè¿™ä¸ªè®¤ä¸ºæ²¡æœ‰è¿›æ­¥
        """
        self.net.train()

        best_loss = float('inf')  # å½“å‰æœ€ä½³loss
        best_state = None  # æœ€ä½³æ¨¡å‹å‚æ•°
        wait_count = 0  # ç­‰å¾…è®¡æ•°å™¨ï¼ˆè€å¿ƒå€¼ç´¯ç§¯ï¼‰

        for step in tqdm(range(self.net.training_steps)):
            # å‰å‘è®¡ç®—
            loss, recon, denoise, Z_, ind_min, ind_max = self.net(
                coord=self.coord,
                node_feats=self.X, 
                count_matrix=self.Y, 
                library_size=self.lY, 
                slice_label=self.slice, 
                basis=self.basis,
                c=self.normalize,
                step=step
            )

            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()

            # æ‰“å°æ—¥å¿—
            if report_loss and step % step_interval == 0:
                print(f"Step {step} | Loss: {loss.item():.6f} | Best: {best_loss:.6f}")

            # ========== æ—©åœåˆ¤æ–­ ==========
            if best_loss - loss.item() > min_delta:
                best_loss = loss.item()
                best_state = {
                    'model': self.net.state_dict(),
                    'optimizer': self.optimizer.state_dict()
                }
                wait_count = 0  # é‡ç½®ç­‰å¾…è®¡æ•°å™¨
            else:
                wait_count += 1

            # å¦‚æœç­‰å¾…æ¬¡æ•°è¶…è¿‡è€å¿ƒå€¼ => æå‰åœæ­¢
            if wait_count >= self.patience:
                print(f"â¹ Early stopping at step {step} | Best loss: {best_loss:.6f}")
                break

        # è®­ç»ƒç»“æŸååŠ è½½æœ€ä½³æ¨¡å‹
        if best_state is not None:
            self.net.load_state_dict(best_state['model'])
            self.optimizer.load_state_dict(best_state['optimizer'])
            print("âœ… Loaded best model state from training.")


    def eval(self, adata_st_list_raw, save=False, output_path="./results"):
        self.net.eval()
        self.Z, self.beta, self.alpha, self.gamma = self.net.evaluate(
            self.coord, self.X, self.slice
        )

        # latent embedding
        embeddings = self.Z.detach().cpu().numpy()
        cell_reps = pd.DataFrame(embeddings)
        cell_reps.index = self.adata_st.obs.index
        self.adata_st.obsm['latent'] = cell_reps.loc[self.adata_st.obs_names, ].values

        self.latent = cell_reps.loc[self.adata_st.obs_names, ].values
        if save:
            cell_reps.to_csv(os.path.join(output_path, "representation.csv"))

        # åå·ç§¯ç»“æœ
        b = self.beta.detach().cpu().numpy()
        n_spots = 0
        adata_st_decon_list = []
        decon_results_all = []  # ç”¨äºä¿å­˜æ‰€æœ‰çš„åå·ç§¯ç»“æœ

        for i, adata_st_i in enumerate(adata_st_list_raw):
            adata_st_i = adata_st_i.copy()

            if self.use_type == 'evaluate':
                if not all(idx.endswith(f"-slice{slice_val}") 
                        for idx, slice_val in zip(adata_st_i.obs.index, adata_st_i.obs['slice'])):
                    adata_st_i.obs.index = [
                        f"{idx}-slice{slice_val}" for idx, slice_val in zip(
                            adata_st_i.obs.index, adata_st_i.obs['slice']
                        )
                    ]
            else:
                if not all(idx.endswith(f"-slice{i}") for idx in adata_st_i.obs.index):
                    adata_st_i.obs.index = [f"{idx}-slice{i}" for idx in adata_st_i.obs.index]

            # ç”Ÿæˆåå·ç§¯ç»“æœ
            decon_res = pd.DataFrame(
                b[n_spots:(n_spots + adata_st_i.shape[0]), :],
                columns=self.celltypes
            )
            decon_res.index = adata_st_i.obs.index
            adata_st_i_obs = adata_st_i.obs.drop(columns=self.celltypes, errors="ignore")
            adata_st_i.obs = adata_st_i_obs.join(decon_res)

            # å°†åå·ç§¯ç»“æœæ·»åŠ åˆ°åˆ—è¡¨ä¸­
            decon_results_all.append(decon_res)

            n_spots += adata_st_i.shape[0]
            adata_st_decon_list.append(adata_st_i)

        # å¦‚æœéœ€è¦ä¿å­˜åå·ç§¯ç»“æœï¼Œå°†æ‰€æœ‰åå·ç§¯ç»“æœåˆå¹¶åä¿å­˜
        if save:
            # å°†åå·ç§¯ç»“æœåˆå¹¶ä¸ºä¸€ä¸ª DataFrame
            decon_results_combined = pd.concat(decon_results_all)
            decon_results_combined.to_csv(os.path.join(output_path, "deconvolution_results.csv"))

        return adata_st_decon_list

    # -------- inference_latent ---------
    def inference_latent(self, adata_new, coord_key="3D_coor", method="distance", 
                        decode=False, deconv=False):
        self.net.eval()
        coord_new = torch.from_numpy(np.array(adata_new.obsm[coord_key])).float().to(self.device)

        with torch.no_grad():
            # ç”¨æ¨¡å‹çš„åˆ‡ç‰‡æ•°é‡æ¥ä¿è¯å’Œ slice_emb æƒé‡é•¿åº¦ä¸€è‡´
            n_slices_model = self.net.slice_emb.weight.data.shape[0]
            centers = []
            for s in range(n_slices_model):
                coords_s = self.adata_st[self.adata_st.obs["slice"] == s].obsm[coord_key]
                centers.append(coords_s.mean(0))
            centers = np.array(centers)

            coords_new_center = np.array(adata_new.obsm[coord_key]).mean(0)
            dists = np.linalg.norm(centers - coords_new_center, axis=1)
            weights = np.exp(-dists / (dists.std() + 1e-8))
            weights = weights / weights.sum()

            slice_embs = self.net.slice_emb.weight.data.cpu().numpy()
            new_slice_emb = (weights[:, None] * slice_embs).sum(0, keepdims=True)
            new_slice_emb = torch.from_numpy(new_slice_emb).float().to(self.device)

            # ä¸´æ—¶æ‰©å±• slice embedding è¡¨
            original_weight = self.net.slice_emb.weight.data.clone()
            self.net.slice_emb.weight = torch.nn.Parameter(
                torch.cat([original_weight, new_slice_emb], dim=0)
            )
            slice_new_id = self.n_slices
            slice_new = torch.full((adata_new.shape[0],), slice_new_id, dtype=torch.long).to(self.device)

            # ç¼–ç 
            Z_new, _ = self.net.inference_encoder(coord_new)
            Z_new = Z_new.float()

            if decode:
                X_pred = self.net.decoder(Z_new)
                adata_new.obsm["X_pred"] = X_pred.cpu().numpy()

            if deconv:
                slice_new_emb = self.net.slice_emb(slice_new).float()
                beta_new, alpha_new = self.net.deconvolutioner(Z_new, slice_new_emb)
                cell_type_props = beta_new.cpu().numpy()

                prop_df = pd.DataFrame(cell_type_props, columns=self.celltypes, index=adata_new.obs.index)
                prop_df.to_csv("cell_type_proportions.csv")
                adata_new.obs = adata_new.obs.drop(columns=self.celltypes, errors="ignore")
                for cell_type in self.celltypes:
                    adata_new.obs[cell_type] = prop_df[cell_type]
               
                adata_new.obsm["cell_type_proportions"] = cell_type_props
                adata_new.obsm["deconv_alpha"] = alpha_new.cpu().numpy()

            # æ¢å¤åŸå§‹ embedding è¡¨
            self.net.slice_emb.weight = torch.nn.Parameter(original_weight)

            adata_new.obsm["latent"] = Z_new.cpu().numpy()

        return adata_new

    